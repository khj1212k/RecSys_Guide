[< ìƒìœ„ í´ë”ë¡œ ì´ë™](README.md)

<details>
<summary><strong>ì „ì²´ íƒìƒ‰ (RecSys ê°€ì´ë“œ)</strong></summary>

- [í™ˆ](../../README.md)
- [01. ì „í†µì  ëª¨ë¸](../../01_Traditional_Models/README.md)
  - [í˜‘ì—… í•„í„°ë§](../../01_Traditional_Models/01_Collaborative_Filtering/README.md)
    - [ë©”ëª¨ë¦¬ ê¸°ë°˜](../../01_Traditional_Models/01_Collaborative_Filtering/01_Memory_Based/README.md)
    - [ëª¨ë¸ ê¸°ë°˜](../../01_Traditional_Models/01_Collaborative_Filtering/02_Model_Based/README.md)
  - [ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§](../../01_Traditional_Models/02_Content_Based_Filtering/README.md)
- [02. ê³¼ë„ê¸° ë° í†µê³„ì  ëª¨ë¸](../../02_Machine_Learning_Era/README.md)
- [03. ë”¥ëŸ¬ë‹ ê¸°ë°˜ ëª¨ë¸](../../03_Deep_Learning_Era/README.md)
  - [MLP ê¸°ë°˜](../../03_Deep_Learning_Era/01_MLP_Based/README.md)
  - [ìˆœì°¨/ì„¸ì…˜ ê¸°ë°˜](../../03_Deep_Learning_Era/02_Sequence_Session_Based/README.md)
  - [ê·¸ë˜í”„ ê¸°ë°˜](../../03_Deep_Learning_Era/03_Graph_Based/README.md)
  - [ì˜¤í† ì¸ì½”ë” ê¸°ë°˜](../../03_Deep_Learning_Era/04_AutoEncoder_Based/README.md)
- [04. ìµœì‹  ë° ìƒì„±í˜• ëª¨ë¸](../../04_SOTA_GenAI/README.md) - [LLM ê¸°ë°˜](../../04_SOTA_GenAI/01_LLM_Based/README.md) - [ë©€í‹°ëª¨ë‹¬ ì¶”ì²œ](../../04_SOTA_GenAI/02_Multimodal_RS.md) - [ìƒì„±í˜• ì¶”ì²œ](../../04_SOTA_GenAI/03_Generative_RS.md)
</details>

# LLM4Rec

## 1. ìƒì„¸ ì„¤ëª… (Detailed Description)

### ì •ì˜ (Definition)

**LLM4Rec**ì€ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(GPT-4, LLaMA, PaLM ë“±)ì„ ì¶”ì²œ ì‘ì—…ì— í™œìš©í•˜ëŠ” ëª¨ë“  ì ‘ê·¼ ë°©ì‹ì„ í†µì¹­í•©ë‹ˆë‹¤. IDì™€ ìƒí˜¸ì‘ìš© í–‰ë ¬ì—ë§Œ ì˜ì¡´í•˜ë˜ ê¸°ì¡´ ëª¨ë¸ê³¼ ë‹¬ë¦¬, LLMì€ ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ ì˜ë¯¸ë¡ ì  ì§€ì‹(World Knowledge)ì„ ì´ë¯¸ í•™ìŠµí•˜ê³  ìˆì–´ ì´ë¥¼ ì¶”ì²œì— í™œìš©í•©ë‹ˆë‹¤.

### íŒ¨ëŸ¬ë‹¤ì„ (Paradigms)

1.  **ì¶”ì²œê¸°ë¡œì„œì˜ LLM (Direct)**: "ì‚¬ìš©ì ê¸°ë¡ì´ A, B, Cì¼ ë•Œ, ë‹¤ìŒì— ë¬´ì—‡ì„ ì‚¬ì•¼ í• ê¹Œ?"ë¼ê³  ì§ˆë¬¸í•˜ë©´ LLMì´ ì§ì ‘ ë‹µë³€.
2.  **íŠ¹ì§• ì¸ì½”ë”ë¡œì„œì˜ LLM (Feature Encoder)**: "ì´ ì˜í™” ì¤„ê±°ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•´ì¤˜" -> ë³€í™˜ëœ ì„ë² ë”©ì„ ê¸°ì¡´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ì£¼ì….
3.  **ë°ì´í„° ìƒì„±ê¸°ë¡œì„œì˜ LLM (Augmentation)**: "ê°€ìƒì˜ ì‚¬ìš©ìë¥¼ ì‹œë®¬ë ˆì´ì…˜í•´ì„œ ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œë¥¼ í•´ê²°í•  ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ì¤˜."

### ì£¼ìš” íŠ¹ì§• (Key Characteristics)

- **ì œë¡œìƒ·/í“¨ìƒ· (Zero-Shot / Few-Shot)**: íŠ¹ì • ë°ì´í„°ì…‹ìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ì§€ ì•Šì•„ë„ ì–´ëŠ ì •ë„ ì¶”ì²œì„ ì˜ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- **ì¶”ë¡  ëŠ¥ë ¥ (Reasoning)**: ì™œ ì´ ì•„ì´í…œì„ ì¶”ì²œí–ˆëŠ”ì§€("ë„¤ê°€ ë””ìŠ¤í† í”¼ì•„ SFë¥¼ ì¢‹ì•„í•˜ë‹ˆê¹Œ...") ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ì¥ì **:
  - ì••ë„ì ì¸ **ì½œë“œ ìŠ¤íƒ€íŠ¸** ì„±ëŠ¥.
  - ìì—°ì–´ ì¸í„°í˜ì´ìŠ¤(Chat-Rec) ê°€ëŠ¥.
- **ë‹¨ì **:
  - **í™˜ê° (Hallucination)**: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì˜í™”ë¥¼ ì¶”ì²œí•  ìˆ˜ ìˆìŒ.
  - **ì§€ì—° ì‹œê°„ (Latency)**: í…ìŠ¤íŠ¸ ìƒì„±ì€ ë‚´ì (Dot Product) ì—°ì‚°ë³´ë‹¤ í›¨ì”¬ ëŠë¦½ë‹ˆë‹¤.
  - **ìœ„ì¹˜ í¸í–¥ (Position Bias)**: í”„ë¡¬í”„íŠ¸ì˜ ì•ìª½ì´ë‚˜ ë’¤ìª½ì— ìˆëŠ” ì•„ì´í…œì„ ë” ì„ í˜¸í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.

---

## 2. ì‘ë™ ì›ë¦¬ (Operating Principle)

### A. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (Prompt Engineering)

í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì€ 'ì§ˆë¬¸ì„ ì˜ ë§Œë“œëŠ” ê²ƒ'ì…ë‹ˆë‹¤.

- **ì§€ì‹œ (Instruction)**: "ë„ˆëŠ” ì˜í™” ì „ë¬¸ê°€ì•¼..."
- **ë§¥ë½ (Context)**: "ì‚¬ìš©ì ê¸°ë¡: [ë§¤íŠ¸ë¦­ìŠ¤, ì¸ì…‰ì…˜, í…Œë„·]"
- **í›„ë³´êµ° (Candidate Set)**: "í›„ë³´: [ë°”ë¹„, ì˜¤íœí•˜ì´ë¨¸, ì¸í„°ìŠ¤í…”ë¼]" (ì„ íƒì  - ë­í‚¹ ëª¨ë“œ ì‹œ)
- **ì‘ì—… (Task)**: "í›„ë³´ë“¤ì˜ ìˆœìœ„ë¥¼ ë§¤ê²¨ì¤˜."

### B. ì¸ì»¨í…ìŠ¤íŠ¸ ëŸ¬ë‹ (In-Context Learning, ICL)

í”„ë¡¬í”„íŠ¸ ì•ˆì— ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ ëª¨ë¸ì´ ì›í•˜ëŠ” í¬ë§·ê³¼ ë…¼ë¦¬ë¥¼ ë”°ë¥´ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.

- Prompt: "ì‚¬ìš©ì AëŠ” X,Yë¥¼ ì¢‹ì•„í•¨ -> ì¶”ì²œ Z. ì‚¬ìš©ì BëŠ” P,Që¥¼ ì¢‹ì•„í•¨ -> ì¶”ì²œ R. ì ì´ì œ ì‚¬ìš©ì CëŠ”..."

### C. íŒŒì¸íŠœë‹ (Instruction Tuning)

LLaMA ê°™ì€ ëª¨ë¸ì„ ê°€ì ¸ì™€ì„œ ìˆ˜ì²œ ê°œì˜ ì¶”ì²œ ì‘ì—…(í‰ì  ì˜ˆì¸¡, ì„¤ëª… ìƒì„±) ë°ì´í„°ë¡œ ì¶”ê°€ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ë¥¼ ì™„ì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì¶”ì²œ ë¡œì§ì„ ë”°ë¥´ë„ë¡ ì •ë ¬(Align)í•©ë‹ˆë‹¤.

---

## 3. íë¦„ ì˜ˆì‹œ (Flow Example)

### ì‹œë‚˜ë¦¬ì˜¤: APIë¥¼ í†µí•œ ì§ì ‘ ì¶”ì²œ

**ì‚¬ìš©ì ê¸°ë¡**: "ë‹¤í¬ ë‚˜ì´íŠ¸", "ì¡°ì»¤".

### 1ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ êµ¬ì„±

```text
System: ì˜í™” ì¶”ì²œ ì „ë¬¸ê°€ë¡œì„œ í–‰ë™í•´.
User: ë‚˜ëŠ” "ë‹¤í¬ ë‚˜ì´íŠ¸" (5/5)ì™€ "ì¡°ì»¤" (4/5)ë¥¼ ë´¤ì–´.
ë‚˜ëŠ” ì‹¬ë¦¬ì  ê¹Šì´ê°€ ìˆëŠ” ì–´ë‘ìš´ íˆì–´ë¡œë¬¼ì„ ì¢‹ì•„í•´.
ì•ˆ ë³¸ ì˜í™” 1ê°œë¥¼ ì¶”ì²œí•´ì¤˜.
```

### 2ë‹¨ê³„: LLM ì¶”ë¡  (ë‚´ë¶€)

1.  **ê¸°ë¡ ë¶„ì„**: ë‹¤í¬ ë‚˜ì´íŠ¸ & ì¡°ì»¤ -> DC ìœ ë‹ˆë²„ìŠ¤, ê³ ë‹´, ê±°ì¹ ê³ (Gritty), ì‹¬ë¦¬ ìŠ¤ë¦´ëŸ¬.
2.  **ì§€ì‹ ê²€ìƒ‰**: ë­ê°€ ë¹„ìŠ·í•˜ì§€? "ë” ë°°íŠ¸ë§¨ (2022)", "ì™“ì¹˜ë§¨", "ë¸Œì´ í¬ ë²¤ë°íƒ€".
3.  **í•„í„°ë§**: "ë” ë°°íŠ¸ë§¨"ì´ ê°€ì¥ ìµœì‹ ì´ê³  ìŠ¤íƒ€ì¼ì´ ë¹„ìŠ·í•¨.

### 3ë‹¨ê³„: ìƒì„± (Generation)

```text
Response: "ë” ë°°íŠ¸ë§¨ (2022)"ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
ì´ìœ : ë‹¹ì‹ ì´ ì¢‹ì•„í•œ ì´ì „ ì˜í™”ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, ê³ ë‹´ ì‹œí‹°ì— ëŒ€í•œ ëˆ„ì•„ë¥´ íƒì •ë¬¼ì  í•´ì„ì„ ë³´ì—¬ì£¼ë©°, 'ì¡°ì»¤'ê°€ ì•„ì„œ í”Œë ‰ì„ íƒêµ¬í–ˆë“¯ì´ ë¸Œë£¨ìŠ¤ ì›¨ì¸ì˜ ì‹¬ë¦¬ë¥¼ ê¹Šì´ ìˆê²Œ ë‹¤ë£¹ë‹ˆë‹¤.
```

### ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TD
    subgraph "LLM4Rec Pipeline"
        direction TB

        %% Data Preparation
        subgraph "1. Data Preparation"
            History["ğŸ“œ User History<br>[Dark Knight, Joker]"]
            Candidates["ğŸ“¦ Candidates (Optional)<br>[Batman, Superman, ...]"]
        end

        %% Prompt Engineering
        subgraph "2. Prompt Engineering"
            Template["ğŸ“ Template<br>'Act as a movie expert...'"]
            Construct["ğŸ› ï¸ Prompt Construction<br>(Inject History & Candidates)"]

            History --> Construct
            Candidates --> Construct
            Template --> Construct

            FinalPrompt["ğŸ“„ Final Prompt<br>'User watched X, Y... Recommend one.'"]
            Construct --> FinalPrompt
        end

        %% LLM Inference
        subgraph "3. LLM Inference"
            Tokenizer["ğŸ”¤ Tokenizer<br>(Text â†’ IDs)"]
            Model["ğŸ§  LLM (Transformer)<br>Self-Attention & Feed-Forward"]
            Logits["ğŸ“Š Next Token Probabilities"]

            FinalPrompt --> Tokenizer
            Tokenizer --> Model
            Model --> Logits
        end

        %% Output
        subgraph "4. Response Generation"
            Sampling["ğŸ² Sampling / Greedy"]
            TextDetoken["ğŸ”  De-tokenizer"]
            Parsed["ğŸ’¡ Parsed Recommendation<br>'The Batman'"]

            Logits --> Sampling
            Sampling --> TextDetoken
            TextDetoken --> Parsed
        end
    end

    %% Styling
    style FinalPrompt fill:#fff9c4,stroke:#fbc02d
    style Model fill:#e1bee7,stroke:#8e24aa
    style Parsed fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
```
